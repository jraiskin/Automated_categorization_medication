{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from utils.utils_nn import *\n",
    "from utils.utils_baseline_svm import *\n",
    "from utils.Rnn_model import Rnn_model\n",
    "# import kwargs dicts\n",
    "from utils.kwargs_file import kwargs_neural_data_init, \\\n",
    "    kwargs_lin_data_init, kwargs_svm  # , kwargs_rnn\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "random.seed(seed())\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--use_suggestions'], dest='use_suggestions', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Should the algorithm use label suggestions (False would mean using only the given labeled data)', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enable passing some keyword arguments from command line.\n",
    "This does not affect the Jupyter notebook.\n",
    "\"\"\"\n",
    "# try:\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--use_suggestions', action='store', dest='use_suggestions',\n",
    "                    help='Should the algorithm use label suggestions '+\\\n",
    "                        '(False would mean using only the given labeled data)', \n",
    "                    type=str, \n",
    "                    default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if args.use_suggestions is not None:\n",
    "    kwargs_neural_data_init.use_suggestions = str(args.use_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "####### IF UNSURE, SKIP THIS CELL #######\n",
    "\n",
    "\n",
    "Plug in manually the suggestion similarity threshold.\n",
    "This is a very hacky solution, for getting all of the results for different thresholds.\n",
    "Done this way because sending a for loop to the cluster takes too much overhead time,\n",
    "on the otherhand, a for loop will use up too much RAM on local machine.\n",
    "\"\"\"\n",
    "# 0.7\n",
    "# 0.8\n",
    "# 0.9\n",
    "# F\n",
    "\n",
    "### DONE:\n",
    "# 0.8\n",
    "# F\n",
    "\n",
    "kwargs_neural_data_init.use_suggestions = 'F'\n",
    "# make sure SVM follows\n",
    "kwargs_lin_data_init.use_suggestions = kwargs_neural_data_init.use_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the correct kwargs file, based on suggestion args\n",
    "suggestion_convert_dict = \\\n",
    "    {'0.7': '07', \n",
    "     '0.8': '08', \n",
    "     '0.9': '09', \n",
    "     'F': '10'}\n",
    "\n",
    "suggestion_str = \\\n",
    "    suggestion_convert_dict[kwargs_neural_data_init.use_suggestions]\n",
    "\n",
    "import_kwargs_str = \\\n",
    "    'from utils.kwargs_file_{} import kwargs_rnn_GRU, kwargs_rnn_LSTM'.format(suggestion_str)\n",
    "\n",
    "exec(import_kwargs_str)  # execute import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using label suggestion data\n",
      "The are 2028 observations\n",
      "Sampling from allowed 47 labels\n",
      "47 labels in the validation set, with\n",
      "783 potential observation to draw from.\n",
      "177 observations sampled for validation\n",
      "606 observations for training\n",
      "The ratio of validation to *training* is about 0.292\n"
     ]
    }
   ],
   "source": [
    "x_feed_train, y_feed_train, x_feed_val, y_feed_val,\\\n",
    "    char_int, char_int_inv, label_int, label_int_inv, \\\n",
    "    statistics_dict =\\\n",
    "    data_load_preprocess(**kwargs_neural_data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal validation to trainig ration is 0.222\n",
      "Maximal validation to trainig ration is 0.333\n"
     ]
    }
   ],
   "source": [
    "#### check if there are any strange splits between training and validation\n",
    "#### e.g. labels (training and validation) don't match exactly\n",
    "#### or not enough (or too many) observation were set aside for validation\n",
    "y_train_counter = Counter(y_feed_train)\n",
    "y_train_labs = list(y_train_counter.keys())\n",
    "y_train_labs.sort()\n",
    "\n",
    "y_val_counter = Counter(y_feed_val)\n",
    "y_val_labs = list(y_val_counter.keys())\n",
    "y_val_labs.sort()\n",
    "\n",
    "assert y_train_labs==y_train_labs, 'Labels in training and validation set do not match!'\n",
    "\n",
    "validation_training_ratios = []\n",
    "for label in y_train_labs:\n",
    "    val_num = y_val_counter[label]\n",
    "    train_num = y_train_counter[label]\n",
    "    ratio = float(val_num / train_num)\n",
    "    validation_training_ratios.append(ratio)\n",
    "#     print('{:.3f}'.format(ratio), label, val_num, train_num)\n",
    "\n",
    "print('Minimal validation to trainig ration is {:.3f}'.format(min(validation_training_ratios)))\n",
    "print('Maximal validation to trainig ration is {:.3f}'.format(max(validation_training_ratios)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns np.arrays to feed into tf model\n",
    "# training data\n",
    "X_train, _, Y_train = index_transorm_xy(x=x_feed_train, \n",
    "                                        y=y_feed_train, \n",
    "                                        char_int=char_int, \n",
    "                                        label_int=label_int, \n",
    "                                        n_class=statistics_dict['n_class'])\n",
    "\n",
    "# validation data\n",
    "X_val, _, Y_val = index_transorm_xy(x=x_feed_val, \n",
    "                                    y=y_feed_val, \n",
    "                                    char_int=char_int, \n",
    "                                    label_int=label_int, \n",
    "                                    n_class=statistics_dict['n_class'])\n",
    "\n",
    "# write a metadata file for embeddings visualizer and create path string\n",
    "embed_vis_path = write_embeddings_metadata(log_dir=kwargs_rnn_GRU.log_dir, \n",
    "                                           dictionary=char_int, \n",
    "                                           file_name='metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs_feed_dict_train = {'x': X_train, 'y': Y_train}\n",
    "kwargs_feed_dict_test = {'x': X_val, 'y': Y_val}\n",
    "\n",
    "kwargs_rnn_GRU = nice_dict({**kwargs_rnn_GRU, **statistics_dict})\n",
    "kwargs_rnn_LSTM = nice_dict({**kwargs_rnn_LSTM, **statistics_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train GRU and LSTM models\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )\n",
    "\n",
    "rnn_GRU_model.train()\n",
    "rnn_GRU_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LSTM model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_LSTM)\n",
    "\n",
    "rnn_LSTM_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_LSTM\n",
    "                      )\n",
    "\n",
    "rnn_LSTM_model.train()\n",
    "rnn_LSTM_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect MRR per ATC code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collect_mrr_per_atc = []\n",
    "collect_obs_num_per_atc = []\n",
    "\n",
    "collected_results_per_atc_code_dir = 'rnn_results/results_per_atc_code/'\n",
    "\n",
    "collected_obs_num_fname = collected_results_per_atc_code_dir + \\\n",
    "    'rnn_svm_obs_num_per_atc_code_sim_{}.p'.format(suggestion_str)\n",
    "collected_mrr_fname = collected_results_per_atc_code_dir + \\\n",
    "    'rnn_svm_results_per_atc_code_sim_{}.p'.format(suggestion_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInitialize SVM\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize SVM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using label suggestion data\n",
      "The are 2028 observations\n",
      "Sampling from allowed 47 labels\n",
      "47 labels in the validation set, with\n",
      "783 potential observation to draw from.\n",
      "177 observations sampled for validation\n",
      "606 observations for training\n",
      "The ratio of validation to *training* is about 0.292\n",
      "X_train_svm (sparse) matrix, of size 606 by 4373 has been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=2178, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "\n",
    "# load data\n",
    "x_train_svm, x_val_svm, \\\n",
    "    y_train_svm, y_val_svm, \\\n",
    "    allowed_ngrams = \\\n",
    "    data_load_preprocess(**{**kwargs_lin_data_init, \n",
    "                            **{'linear_counters': False}})\n",
    "\n",
    "# create and fit classifier\n",
    "# create a sparse X matrix with character and n-grams features\n",
    "X_train_svm = v.fit_transform([Counter(elem) for elem in x_train_svm])\n",
    "X_val_svm = v.transform([Counter(elem) for elem in x_val_svm])\n",
    "\n",
    "print('X_train_svm (sparse) matrix, of size {} by {} has been created.'\n",
    "      .format(X_train_svm.get_shape()[0], \n",
    "              X_train_svm.get_shape()[1]))  # vectorized\n",
    "\n",
    "svm_clf = svm.SVC(**kwargs_svm)\n",
    "\n",
    "# print(svm_clf)\n",
    "\n",
    "svm_clf.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# array to hold log probabilities (takes a bit longer to calc)\n",
    "pred_prob_svm = svm_clf.predict_log_proba(X_val_svm)\n",
    "# makes y into array with the same shape as the log prob\n",
    "y_val_svm_dense = y_to_dense(y=y_val_svm, \n",
    "                         classes=svm_clf.classes_)\n",
    "\n",
    "recip_rank_array_svm = \\\n",
    "    mean_reciprocal_rank(\n",
    "        y_val_svm_dense, \n",
    "        pred_prob_svm, \n",
    "        average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_mrr = OrderedDict()\n",
    "row_obs_num = OrderedDict()\n",
    "\n",
    "# init a dict of empty lists\n",
    "for atc in svm_clf.classes_:\n",
    "    row_mrr[atc] = []\n",
    "#     row_obs_num[atc] = []\n",
    "\n",
    "# create lists of reciprocal ranks\n",
    "for atc, recip_rank in zip(y_val_svm, recip_rank_array_svm):\n",
    "    row_mrr[atc].append(recip_rank)\n",
    "\n",
    "# calculate MRR\n",
    "for k,v in row_mrr.items():\n",
    "    row_mrr[k] = np.mean(v)\n",
    "    row_obs_num[k] = len(v)\n",
    "\n",
    "row_mrr['Similarity'] = int(suggestion_str) / 10\n",
    "row_obs_num['Similarity'] = int(suggestion_str) / 10\n",
    "row_mrr['Model type'] = 'SVM'\n",
    "row_obs_num['Model type'] = 'SVM'\n",
    "\n",
    "row_mrr.move_to_end('Model type', last=False)\n",
    "row_obs_num.move_to_end('Model type', last=False)\n",
    "row_mrr.move_to_end('Similarity', last=False)\n",
    "row_obs_num.move_to_end('Similarity', last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect results\n",
    "collect_mrr_per_atc.append(row_mrr)\n",
    "collect_obs_num_per_atc.append(row_obs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get MRR per ATC code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(kwargs_feed_dict_train['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs_rnn_GRU.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs_rnn_GRU.n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from rnn_final_batch_trained_models/sim_10/GRU,bidir=F,noisy_tanh,learn_p=F,noise_alpha=0.9,noise_half_normal=T,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=1.0,one_hot,hidden_state_size=128,l2_weight_reg=1.0E-02,target_rep_weight=0.3/\n",
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "rnn_GRU_model.restore(kwargs_rnn_GRU.log_dir+hparam_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LSTM model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_LSTM)\n",
    "\n",
    "rnn_LSTM_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_LSTM\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from rnn_final_batch_trained_models/sim_10/LSTM,bidir=F,noisy_tanh,learn_p=T,noise_alpha=1.15,noise_half_normal=T,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=0.7,one_hot,hidden_state_size=128,l2_weight_reg=1.0E-03,target_rep_weight=0.5/\n",
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "rnn_LSTM_model.restore(kwargs_rnn_LSTM.log_dir+hparam_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mrr_per_atc(Rnn_model_inst):\n",
    "    \"\"\"\n",
    "    Returns two OrderedDict's, MRR per ATC code and number of observations per ATC code\n",
    "    Assumes that th efile was run with the same suggestion settings and x,y inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    [accuracy, cost, recip_rank, top_k, logits] = \\\n",
    "        Rnn_model_inst.run_eval()\n",
    "\n",
    "    # get an array of reciprocal ranks\n",
    "    with tf.Session() as sess:\n",
    "        recip_rank_array = \\\n",
    "            Rnn_model_inst.get_reciprocal_rank(\n",
    "                logits=logits, \n",
    "                targets=kwargs_feed_dict_test['y']).eval()\n",
    "\n",
    "    row_mrr = OrderedDict()\n",
    "    \n",
    "    row_obs_num = OrderedDict()\n",
    "    row_obs_num['Similarity'] = int(suggestion_str) / 10\n",
    "    row_obs_num['Model type'] = Rnn_model_inst.rnn_type\n",
    "    \n",
    "    # init a dict of empty lists\n",
    "    for atc in set(y_feed_val):\n",
    "        row_mrr[atc] = []\n",
    "\n",
    "    # create lists of reciprocal ranks\n",
    "    for atc, recip_rank in zip(y_feed_val, recip_rank_array):\n",
    "        row_mrr[atc].append(recip_rank)\n",
    "\n",
    "    # calculate MRR\n",
    "    for k,v in row_mrr.items():\n",
    "        row_mrr[k] = np.mean(v)\n",
    "        row_obs_num[k] = len(v)\n",
    "\n",
    "    row_mrr['Similarity'] = int(suggestion_str) / 10\n",
    "    row_mrr['Model type'] = Rnn_model_inst.rnn_type\n",
    "\n",
    "    row_mrr.move_to_end('Model type', last=False)\n",
    "    row_mrr.move_to_end('Similarity', last=False)\n",
    "    \n",
    "    return row_mrr, row_obs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_mrr_GRU, row_obs_num_GRU = \\\n",
    "    get_mrr_per_atc(rnn_GRU_model)\n",
    "\n",
    "collect_mrr_per_atc.append(row_mrr_GRU)\n",
    "collect_obs_num_per_atc.append(row_obs_num_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_mrr_LSTM, row_obs_num_LSTM = \\\n",
    "    get_mrr_per_atc(rnn_LSTM_model)\n",
    "\n",
    "collect_mrr_per_atc.append(row_mrr_LSTM)\n",
    "collect_obs_num_per_atc.append(row_obs_num_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the 3 results (SVM, LSTM, GRU) to pickle file format\n",
    "# for each of the two statistics (MRR and count)\n",
    "save(fname=collected_mrr_fname, \n",
    "     obj=collect_mrr_per_atc)\n",
    "\n",
    "save(fname=collected_obs_num_fname, \n",
    "     obj=collect_obs_num_per_atc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
