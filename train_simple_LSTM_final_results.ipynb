{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from utils.utils_nn import *\n",
    "from utils.Rnn_model import Rnn_model\n",
    "# import kwargs dicts\n",
    "from utils.kwargs_file import kwargs_neural_data_init  # , kwargs_rnn\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed())\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import random\n",
    "random.seed(seed())\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--use_suggestions'], dest='use_suggestions', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Should the algorithm use label suggestions (False would mean using only the given labeled data)', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enable passing some keyword arguments from command line.\n",
    "This does not affect the Jupyter notebook.\n",
    "\"\"\"\n",
    "# try:\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--use_suggestions', action='store', dest='use_suggestions',\n",
    "                    help='Should the algorithm use label suggestions '+\\\n",
    "                        '(False would mean using only the given labeled data)', \n",
    "                    type=str, \n",
    "                    default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if args.use_suggestions is not None:\n",
    "    kwargs_neural_data_init.use_suggestions = str(args.use_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the correct kwargs file, based on suggestion args\n",
    "suggestion_convert_dict = \\\n",
    "    {'0.7': '07', \n",
    "     '0.8': '08', \n",
    "     '0.9': '09', \n",
    "     'F': '10', \n",
    "     'False': '10'}\n",
    "\n",
    "suggestion_str = \\\n",
    "    suggestion_convert_dict[kwargs_neural_data_init.use_suggestions]\n",
    "\n",
    "import_kwargs_str = \\\n",
    "    'from utils.kwargs_file_{} import kwargs_rnn_GRU, kwargs_rnn_LSTM'.format(suggestion_str)\n",
    "\n",
    "exec(import_kwargs_str)  # execute import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label suggestion data with similarity threshold of 0.8\n",
      "The are 3565 observations\n",
      "Sampling from allowed 96 labels\n",
      "96 labels in the validation set, with\n",
      "2111 potential observation to draw from.\n",
      "480 observations sampled for validation\n",
      "1631 observations for training\n",
      "The ratio of validation to *training* is about 0.294\n"
     ]
    }
   ],
   "source": [
    "x_feed_train, y_feed_train, x_feed_val, y_feed_val,\\\n",
    "    char_int, char_int_inv, label_int, label_int_inv, \\\n",
    "    statistics_dict =\\\n",
    "    data_load_preprocess(**kwargs_neural_data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal validation to trainig ration is 0.100\n",
      "Maximal validation to trainig ration is 0.333\n"
     ]
    }
   ],
   "source": [
    "#### check if there are any strange splits between training and validation\n",
    "#### e.g. labels (training and validation) don't match exactly\n",
    "#### or not enough (or too many) observation were set aside for validation\n",
    "y_train_counter = Counter(y_feed_train)\n",
    "y_train_labs = list(y_train_counter.keys())\n",
    "y_train_labs.sort()\n",
    "\n",
    "y_val_counter = Counter(y_feed_val)\n",
    "y_val_labs = list(y_val_counter.keys())\n",
    "y_val_labs.sort()\n",
    "\n",
    "assert y_train_labs==y_train_labs, 'Labels in training and validation set do not match!'\n",
    "\n",
    "validation_training_ratios = []\n",
    "for label in y_train_labs:\n",
    "    val_num = y_val_counter[label]\n",
    "    train_num = y_train_counter[label]\n",
    "    ratio = float(val_num / train_num)\n",
    "    validation_training_ratios.append(ratio)\n",
    "#     print('{:.3f}'.format(ratio), label, val_num, train_num)\n",
    "\n",
    "print('Minimal validation to trainig ration is {:.3f}'.format(min(validation_training_ratios)))\n",
    "print('Maximal validation to trainig ration is {:.3f}'.format(max(validation_training_ratios)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns np.arrays to feed into tf model\n",
    "# training data\n",
    "X_train, _, Y_train = index_transorm_xy(x=x_feed_train, \n",
    "                                        y=y_feed_train, \n",
    "                                        char_int=char_int, \n",
    "                                        label_int=label_int, \n",
    "                                        n_class=statistics_dict['n_class'])\n",
    "\n",
    "# validation data\n",
    "X_val, _, Y_val = index_transorm_xy(x=x_feed_val, \n",
    "                                    y=y_feed_val, \n",
    "                                    char_int=char_int, \n",
    "                                    label_int=label_int, \n",
    "                                    n_class=statistics_dict['n_class'])\n",
    "\n",
    "# write a metadata file for embeddings visualizer and create path string\n",
    "embed_vis_path = write_embeddings_metadata(log_dir=kwargs_rnn_GRU.log_dir, \n",
    "                                           dictionary=char_int, \n",
    "                                           file_name='metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs_feed_dict_train = {'x': X_train, 'y': Y_train}\n",
    "kwargs_feed_dict_test = {'x': X_val, 'y': Y_val}\n",
    "\n",
    "kwargs_rnn_GRU = nice_dict({**kwargs_rnn_GRU, **statistics_dict})\n",
    "kwargs_rnn_LSTM = nice_dict({**kwargs_rnn_LSTM, **statistics_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train GRU and LSTM models\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )\n",
    "\n",
    "rnn_GRU_model.train()\n",
    "rnn_GRU_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LSTM model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_LSTM)\n",
    "\n",
    "rnn_LSTM_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_LSTM\n",
    "                      )\n",
    "\n",
    "rnn_LSTM_model.train()\n",
    "rnn_LSTM_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get MRR per ATC code CPU utilization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from rnn_final_batch/sim_08/GRU,bidir=T,noisy_tanh,learn_p=F,noise_alpha=0.9,noise_half_normal=F,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=0.7,one_hot,hidden_state_size=128,l2_weight_reg=1.0E-03,target_rep_weight=0.5/\n",
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )\n",
    "\n",
    "rnn_GRU_model.restore(kwargs_rnn_GRU.log_dir+hparam_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[accuracy, cost, recip_rank, top_k, logits] = \\\n",
    "    rnn_GRU_model.run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 96)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_GRU_model.n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 80)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kwargs_feed_dict_test['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 96)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kwargs_feed_dict_test['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs_feed_dict_test['y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(kwargs_feed_dict_test['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(\n",
    "[np.argmax(kwargs_feed_dict_test['y'][i]) for i in range(np.shape(kwargs_feed_dict_test['y'])[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(\n",
    "list(range(rnn_GRU_model.n_class))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L04AX03'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_int_inv[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L04AX03'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_int_inv[np.argmax(logits[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kwargs_feed_dict_test['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L04AX03'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_feed_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.33333334\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          0.5\n",
      "  1.          0.07142857  1.          1.          1.          1.          1.\n",
      "  0.5         1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          0.2\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.14285715\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.5         1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.25        1.\n",
      "  1.          1.          0.14285715  1.          1.          1.          1.\n",
      "  1.          1.          0.04166667  1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.1         1.          1.\n",
      "  0.14285715  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          0.02380952  1.          1.          0.25        1.\n",
      "  1.          1.          0.03225806  1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  0.5         1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  0.25        1.          1.          1.          1.          1.          1.\n",
      "  1.          0.33333334  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          0.07692308  1.          1.          1.\n",
      "  1.          0.07692308  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          0.33333334  1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.05555556  1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  0.01960784  1.          1.          1.          1.          1.          0.5\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.02857143  1.          1.\n",
      "  1.          1.          1.          0.1         1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          0.25        1.          1.          1.          1.          1.\n",
      "  1.          0.33333334  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.01785714  1.          1.\n",
      "  1.          1.          0.05263158  1.          1.          1.          1.\n",
      "  0.06666667  1.          1.          1.          1.          1.\n",
      "  0.03571429  1.          1.          1.          1.          1.\n",
      "  0.33333334  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.03125     0.5\n",
      "  1.          1.          1.          1.          0.03125     1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          0.5         1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.        ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\n",
    "    rnn_GRU_model.get_reciprocal_rank(logits=logits, \n",
    "                                      targets=kwargs_feed_dict_test['y']).eval()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
