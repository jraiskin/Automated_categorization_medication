{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from utils.utils_nn import *\n",
    "from utils.utils_baseline_svm import *\n",
    "from utils.Rnn_model import Rnn_model\n",
    "# import kwargs dicts\n",
    "from utils.kwargs_file import kwargs_neural_data_init, \\\n",
    "    kwargs_lin_data_init, kwargs_svm  # , kwargs_rnn\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "random.seed(seed())\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--use_suggestions'], dest='use_suggestions', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Should the algorithm use label suggestions (False would mean using only the given labeled data)', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enable passing some keyword arguments from command line.\n",
    "This does not affect the Jupyter notebook.\n",
    "\"\"\"\n",
    "# try:\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--use_suggestions', action='store', dest='use_suggestions',\n",
    "                    help='Should the algorithm use label suggestions '+\\\n",
    "                        '(False would mean using only the given labeled data)', \n",
    "                    type=str, \n",
    "                    default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if args.use_suggestions is not None:\n",
    "    kwargs_neural_data_init.use_suggestions = str(args.use_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "####### IF UNSURE, SKIP THIS CELL #######\n",
    "\n",
    "\n",
    "Plug in manually the suggestion similarity threshold.\n",
    "This is a very hacky solution, for getting all of the results for different thresholds.\n",
    "Done this way because sending a for loop to the cluster takes too much overhead time,\n",
    "on the otherhand, a for loop will use up too much RAM on local machine.\n",
    "\"\"\"\n",
    "# 0.7\n",
    "# 0.8\n",
    "# 0.9\n",
    "# F\n",
    "\n",
    "### DONE:\n",
    "# 0.8\n",
    "# F\n",
    "\n",
    "kwargs_neural_data_init.use_suggestions = 'F'\n",
    "# make sure SVM follows\n",
    "kwargs_lin_data_init.use_suggestions = kwargs_neural_data_init.use_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the correct kwargs file, based on suggestion args\n",
    "suggestion_convert_dict = \\\n",
    "    {'0.7': '07', \n",
    "     '0.8': '08', \n",
    "     '0.9': '09', \n",
    "     'F': '10'}\n",
    "\n",
    "suggestion_str = \\\n",
    "    suggestion_convert_dict[kwargs_neural_data_init.use_suggestions]\n",
    "\n",
    "import_kwargs_str = \\\n",
    "    'from utils.kwargs_file_{} import kwargs_rnn_GRU, kwargs_rnn_LSTM'.format(suggestion_str)\n",
    "\n",
    "exec(import_kwargs_str)  # execute import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using label suggestion data\n",
      "The are 2028 observations\n",
      "Sampling from allowed 47 labels\n",
      "47 labels in the validation set, with\n",
      "783 potential observation to draw from.\n",
      "177 observations sampled for validation\n",
      "606 observations for training\n",
      "The ratio of validation to *training* is about 0.292\n"
     ]
    }
   ],
   "source": [
    "x_feed_train, y_feed_train, x_feed_val, y_feed_val,\\\n",
    "    char_int, char_int_inv, label_int, label_int_inv, \\\n",
    "    statistics_dict =\\\n",
    "    data_load_preprocess(**kwargs_neural_data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal validation to trainig ration is 0.222\n",
      "Maximal validation to trainig ration is 0.333\n"
     ]
    }
   ],
   "source": [
    "#### check if there are any strange splits between training and validation\n",
    "#### e.g. labels (training and validation) don't match exactly\n",
    "#### or not enough (or too many) observation were set aside for validation\n",
    "y_train_counter = Counter(y_feed_train)\n",
    "y_train_labs = list(y_train_counter.keys())\n",
    "y_train_labs.sort()\n",
    "\n",
    "y_val_counter = Counter(y_feed_val)\n",
    "y_val_labs = list(y_val_counter.keys())\n",
    "y_val_labs.sort()\n",
    "\n",
    "assert y_train_labs==y_train_labs, 'Labels in training and validation set do not match!'\n",
    "\n",
    "validation_training_ratios = []\n",
    "for label in y_train_labs:\n",
    "    val_num = y_val_counter[label]\n",
    "    train_num = y_train_counter[label]\n",
    "    ratio = float(val_num / train_num)\n",
    "    validation_training_ratios.append(ratio)\n",
    "#     print('{:.3f}'.format(ratio), label, val_num, train_num)\n",
    "\n",
    "print('Minimal validation to trainig ration is {:.3f}'.format(min(validation_training_ratios)))\n",
    "print('Maximal validation to trainig ration is {:.3f}'.format(max(validation_training_ratios)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# returns np.arrays to feed into tf model\n",
    "# training data\n",
    "X_train, _, Y_train = index_transorm_xy(x=x_feed_train, \n",
    "                                        y=y_feed_train, \n",
    "                                        char_int=char_int, \n",
    "                                        label_int=label_int, \n",
    "                                        n_class=statistics_dict['n_class'])\n",
    "\n",
    "# validation data\n",
    "X_val, _, Y_val = index_transorm_xy(x=x_feed_val, \n",
    "                                    y=y_feed_val, \n",
    "                                    char_int=char_int, \n",
    "                                    label_int=label_int, \n",
    "                                    n_class=statistics_dict['n_class'])\n",
    "\n",
    "# write a metadata file for embeddings visualizer and create path string\n",
    "embed_vis_path = write_embeddings_metadata(log_dir=kwargs_rnn_GRU.log_dir, \n",
    "                                           dictionary=char_int, \n",
    "                                           file_name='metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwargs_feed_dict_train = {'x': X_train, 'y': Y_train}\n",
    "kwargs_feed_dict_test = {'x': X_val, 'y': Y_val}\n",
    "\n",
    "kwargs_rnn_GRU = nice_dict({**kwargs_rnn_GRU, **statistics_dict})\n",
    "kwargs_rnn_LSTM = nice_dict({**kwargs_rnn_LSTM, **statistics_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train GRU and LSTM models\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )\n",
    "\n",
    "rnn_GRU_model.train()\n",
    "rnn_GRU_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LSTM model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_LSTM)\n",
    "\n",
    "rnn_LSTM_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_LSTM\n",
    "                      )\n",
    "\n",
    "rnn_LSTM_model.train()\n",
    "rnn_LSTM_model.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect MRR per ATC code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collect_mrr_per_atc = []\n",
    "collect_obs_num_per_atc = []\n",
    "\n",
    "collected_results_per_atc_code_dir = 'rnn_results/results_per_atc_code/'\n",
    "\n",
    "collected_obs_num_fname = collected_results_per_atc_code_dir + \\\n",
    "    'rnn_svm_obs_num_per_atc_code_sim_{}.p'.format(suggestion_str)\n",
    "collected_mrr_fname = collected_results_per_atc_code_dir + \\\n",
    "    'rnn_svm_results_per_atc_code_sim_{}.p'.format(suggestion_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize SVM and get MRR per ATC code\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using label suggestion data\n",
      "The are 2028 observations\n",
      "Sampling from allowed 47 labels\n",
      "47 labels in the validation set, with\n",
      "783 potential observation to draw from.\n",
      "177 observations sampled for validation\n",
      "606 observations for training\n",
      "The ratio of validation to *training* is about 0.292\n",
      "X_train_svm (sparse) matrix, of size 606 by 4373 has been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=2178, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "\n",
    "# load data\n",
    "x_train_svm, x_val_svm, \\\n",
    "    y_train_svm, y_val_svm, \\\n",
    "    allowed_ngrams = \\\n",
    "    data_load_preprocess(**{**kwargs_lin_data_init, \n",
    "                            **{'linear_counters': False}})\n",
    "\n",
    "# create and fit classifier\n",
    "# create a sparse X matrix with character and n-grams features\n",
    "X_train_svm = v.fit_transform([Counter(elem) for elem in x_train_svm])\n",
    "X_val_svm = v.transform([Counter(elem) for elem in x_val_svm])\n",
    "\n",
    "print('X_train_svm (sparse) matrix, of size {} by {} has been created.'\n",
    "      .format(X_train_svm.get_shape()[0], \n",
    "              X_train_svm.get_shape()[1]))  # vectorized\n",
    "\n",
    "svm_clf = svm.SVC(**kwargs_svm)\n",
    "\n",
    "# print(svm_clf)\n",
    "\n",
    "svm_clf.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# array to hold log probabilities (takes a bit longer to calc)\n",
    "pred_prob_svm = svm_clf.predict_log_proba(X_val_svm)\n",
    "# makes y into array with the same shape as the log prob\n",
    "y_val_svm_dense = y_to_dense(y=y_val_svm, \n",
    "                         classes=svm_clf.classes_)\n",
    "\n",
    "recip_rank_array_svm = \\\n",
    "    mean_reciprocal_rank(\n",
    "        y_val_svm_dense, \n",
    "        pred_prob_svm, \n",
    "        average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get SVM MRR per ATC code\n",
    "\n",
    "row_mrr = OrderedDict()\n",
    "row_obs_num = OrderedDict()\n",
    "\n",
    "# init a dict of empty lists\n",
    "for atc in svm_clf.classes_:\n",
    "    row_mrr[atc] = []\n",
    "#     row_obs_num[atc] = []\n",
    "\n",
    "# create lists of reciprocal ranks\n",
    "for atc, recip_rank in zip(y_val_svm, recip_rank_array_svm):\n",
    "    row_mrr[atc].append(recip_rank)\n",
    "\n",
    "# calculate MRR\n",
    "for k,v in row_mrr.items():\n",
    "    row_mrr[k] = np.mean(v)\n",
    "    row_obs_num[k] = len(v)\n",
    "\n",
    "row_mrr['Similarity'] = int(suggestion_str) / 10\n",
    "row_obs_num['Similarity'] = int(suggestion_str) / 10\n",
    "row_mrr['Model type'] = 'SVM'\n",
    "row_obs_num['Model type'] = 'SVM'\n",
    "\n",
    "row_mrr.move_to_end('Model type', last=False)\n",
    "row_obs_num.move_to_end('Model type', last=False)\n",
    "row_mrr.move_to_end('Similarity', last=False)\n",
    "row_obs_num.move_to_end('Similarity', last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect results\n",
    "collect_mrr_per_atc.append(row_mrr)\n",
    "collect_obs_num_per_atc.append(row_obs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize GRU, LSTM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### GRU model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_GRU)\n",
    "\n",
    "rnn_GRU_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_GRU\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from rnn_final_batch_trained_models/sim_10/GRU,bidir=F,noisy_tanh,learn_p=F,noise_alpha=0.9,noise_half_normal=T,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=1.0,one_hot,hidden_state_size=128,l2_weight_reg=1.0E-02,target_rep_weight=0.3/\n",
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "rnn_GRU_model.restore(kwargs_rnn_GRU.log_dir+hparam_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### LSTM model\n",
    "hparam_str = make_hparam_string(**kwargs_rnn_LSTM)\n",
    "\n",
    "rnn_LSTM_model = Rnn_model(hparam_str=hparam_str, \n",
    "                      embed_vis_path=embed_vis_path, \n",
    "                      feed_dict_train=kwargs_feed_dict_train, \n",
    "                      feed_dict_test=kwargs_feed_dict_test, \n",
    "                **kwargs_rnn_LSTM\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading variables from rnn_final_batch_trained_models/sim_10/LSTM,bidir=F,noisy_tanh,learn_p=T,noise_alpha=1.15,noise_half_normal=T,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=0.7,one_hot,hidden_state_size=128,l2_weight_reg=1.0E-03,target_rep_weight=0.5/\n",
      "Loading successful\n"
     ]
    }
   ],
   "source": [
    "rnn_LSTM_model.restore(kwargs_rnn_LSTM.log_dir+hparam_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Log MRR per ATC code for RNNs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mrr_per_atc(Rnn_model_inst):\n",
    "    \"\"\"\n",
    "    Returns two OrderedDict's, MRR per ATC code and number of observations per ATC code\n",
    "    Assumes that th efile was run with the same suggestion settings and x,y inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    [accuracy, cost, recip_rank, top_k, logits] = \\\n",
    "        Rnn_model_inst.run_eval()\n",
    "\n",
    "    # get an array of reciprocal ranks\n",
    "    with tf.Session() as sess:\n",
    "        recip_rank_array = \\\n",
    "            Rnn_model_inst.get_reciprocal_rank(\n",
    "                logits=logits, \n",
    "                targets=kwargs_feed_dict_test['y']).eval()\n",
    "\n",
    "    row_mrr = OrderedDict()\n",
    "    \n",
    "    row_obs_num = OrderedDict()\n",
    "    row_obs_num['Similarity'] = int(suggestion_str) / 10\n",
    "    row_obs_num['Model type'] = Rnn_model_inst.rnn_type\n",
    "    \n",
    "    # init a dict of empty lists\n",
    "    for atc in set(y_feed_val):\n",
    "        row_mrr[atc] = []\n",
    "\n",
    "    # create lists of reciprocal ranks\n",
    "    for atc, recip_rank in zip(y_feed_val, recip_rank_array):\n",
    "        row_mrr[atc].append(recip_rank)\n",
    "\n",
    "    # calculate MRR\n",
    "    for k,v in row_mrr.items():\n",
    "        row_mrr[k] = np.mean(v)\n",
    "        row_obs_num[k] = len(v)\n",
    "\n",
    "    row_mrr['Similarity'] = int(suggestion_str) / 10\n",
    "    row_mrr['Model type'] = Rnn_model_inst.rnn_type\n",
    "\n",
    "    row_mrr.move_to_end('Model type', last=False)\n",
    "    row_mrr.move_to_end('Similarity', last=False)\n",
    "    \n",
    "    return row_mrr, row_obs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRU: log MRR per ATC code\n",
    "row_mrr_GRU, row_obs_num_GRU = \\\n",
    "    get_mrr_per_atc(rnn_GRU_model)\n",
    "\n",
    "collect_mrr_per_atc.append(row_mrr_GRU)\n",
    "collect_obs_num_per_atc.append(row_obs_num_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSTM: log MRR per ATC code\n",
    "row_mrr_LSTM, row_obs_num_LSTM = \\\n",
    "    get_mrr_per_atc(rnn_LSTM_model)\n",
    "\n",
    "collect_mrr_per_atc.append(row_mrr_LSTM)\n",
    "collect_obs_num_per_atc.append(row_obs_num_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the 3 results (SVM, LSTM, GRU) to pickle file format\n",
    "# for each of the two statistics (MRR and count)\n",
    "save(fname=collected_mrr_fname, \n",
    "     obj=collect_mrr_per_atc)\n",
    "\n",
    "save(fname=collected_obs_num_fname, \n",
    "     obj=collect_obs_num_per_atc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Construct data for varying prescription string length\n",
    "Then log MRR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with sequence length 1\n",
      "Starting with sequence length 2\n",
      "Starting with sequence length 3\n",
      "Starting with sequence length 4\n",
      "Starting with sequence length 5\n",
      "Starting with sequence length 6\n",
      "Starting with sequence length 7\n",
      "Starting with sequence length 8\n",
      "Starting with sequence length 9\n",
      "Starting with sequence length 10\n",
      "Starting with sequence length 11\n",
      "Starting with sequence length 12\n",
      "Starting with sequence length 13\n",
      "Starting with sequence length 14\n",
      "Starting with sequence length 15\n",
      "Starting with sequence length 16\n",
      "Starting with sequence length 17\n",
      "Starting with sequence length 18\n",
      "Starting with sequence length 19\n",
      "Starting with sequence length 20\n",
      "Starting with sequence length 21\n",
      "Starting with sequence length 22\n",
      "Starting with sequence length 23\n",
      "Starting with sequence length 24\n",
      "Starting with sequence length 25\n",
      "Starting with sequence length 26\n",
      "Starting with sequence length 27\n",
      "Starting with sequence length 28\n",
      "Starting with sequence length 29\n",
      "Starting with sequence length 30\n",
      "Starting with sequence length 31\n",
      "Starting with sequence length 32\n",
      "Starting with sequence length 33\n",
      "Starting with sequence length 34\n",
      "Starting with sequence length 35\n",
      "Starting with sequence length 36\n",
      "Starting with sequence length 37\n",
      "Starting with sequence length 38\n",
      "Starting with sequence length 39\n",
      "Starting with sequence length 40\n",
      "Starting with sequence length 41\n",
      "Starting with sequence length 42\n",
      "Starting with sequence length 43\n",
      "Starting with sequence length 44\n",
      "Starting with sequence length 45\n",
      "Starting with sequence length 46\n",
      "Starting with sequence length 47\n",
      "Starting with sequence length 48\n",
      "Starting with sequence length 49\n",
      "Starting with sequence length 50\n",
      "Starting with sequence length 51\n",
      "Starting with sequence length 52\n",
      "Starting with sequence length 53\n",
      "Starting with sequence length 54\n",
      "Starting with sequence length 55\n",
      "Starting with sequence length 56\n",
      "Starting with sequence length 57\n",
      "Starting with sequence length 58\n",
      "Starting with sequence length 59\n",
      "Starting with sequence length 60\n",
      "Starting with sequence length 61\n",
      "Starting with sequence length 62\n",
      "Starting with sequence length 63\n",
      "Starting with sequence length 64\n",
      "Starting with sequence length 65\n",
      "Starting with sequence length 66\n",
      "Starting with sequence length 67\n",
      "Starting with sequence length 68\n",
      "Starting with sequence length 69\n",
      "Starting with sequence length 70\n",
      "Starting with sequence length 71\n",
      "Starting with sequence length 72\n",
      "Starting with sequence length 73\n",
      "Starting with sequence length 74\n",
      "Starting with sequence length 75\n",
      "Starting with sequence length 76\n",
      "Starting with sequence length 77\n",
      "Starting with sequence length 78\n",
      "Starting with sequence length 79\n",
      "Starting with sequence length 80\n"
     ]
    }
   ],
   "source": [
    "mrr_per_seq_len_SVM = OrderedDict()\n",
    "mrr_per_seq_len_SVM['Model'] = 'SVM'\n",
    "mrr_per_seq_len_SVM['Similarity'] = int(suggestion_str) / 10\n",
    "\n",
    "mrr_per_seq_len_GRU = OrderedDict()\n",
    "mrr_per_seq_len_GRU['Model'] = 'GRU'\n",
    "mrr_per_seq_len_GRU['Similarity'] = int(suggestion_str) / 10\n",
    "\n",
    "mrr_per_seq_len_LSTM = OrderedDict()\n",
    "mrr_per_seq_len_LSTM['Model'] = 'LSTM'\n",
    "mrr_per_seq_len_LSTM['Similarity'] = int(suggestion_str) / 10\n",
    "\n",
    "# make a copy of feed dicts to the RNN\n",
    "kwargs_feed_dict_test_seq_len_rnn = kwargs_feed_dict_test\n",
    "\n",
    "# makes y into array with the same shape as the log prob\n",
    "y_val_svm_dense = y_to_dense(y=y_val_svm, \n",
    "                         classes=svm_clf.classes_)\n",
    "\n",
    "# for seq_len in range(1,5+1):\n",
    "for seq_len in range(1,kwargs_rnn_GRU.seq_len+1):\n",
    "    print('Starting with sequence length {}'.format(seq_len))\n",
    "    #### SVM data ####\n",
    "    x_val_seq_len_svm = \\\n",
    "        keep_first_k_chars(input=x_val_svm, k=seq_len, \n",
    "                   model='linear', \n",
    "                   ngram_width=kwargs_lin_data_init.ngram_width, \n",
    "                   mk_ngrams=kwargs_lin_data_init.mk_ngrams, \n",
    "                   allowed_ngrams=allowed_ngrams)\n",
    "    \n",
    "    # create a sparse X matrix with character and n-grams features\n",
    "    X_val_seq_len_svm = v.transform([Counter(elem) \n",
    "                                     for elem in x_val_seq_len_svm])\n",
    "    \n",
    "    # array to hold log probabilities (takes a bit longer to calc)\n",
    "    pred_prob_seq_len_svm = \\\n",
    "        svm_clf.predict_log_proba(X_val_seq_len_svm)\n",
    "    \n",
    "    mrr_svm = \\\n",
    "        mean_reciprocal_rank(\n",
    "            y_val_svm_dense, \n",
    "            pred_prob_seq_len_svm)\n",
    "    \n",
    "    ## log MRR for SVM ##\n",
    "    mrr_per_seq_len_SVM[seq_len] = mrr_svm\n",
    "    \n",
    "    #### RNN data ####\n",
    "    kwargs_feed_dict_test_seq_len_rnn['x'] = \\\n",
    "        keep_first_k_chars(input=X_val, k=seq_len, \n",
    "                               model='neural', \n",
    "                               char_int=char_int)\n",
    "    \n",
    "    # update test feed dictionaries\n",
    "    rnn_GRU_model.update_test_dict(\n",
    "        feed_dict_test=kwargs_feed_dict_test_seq_len_rnn)\n",
    "\n",
    "    rnn_LSTM_model.update_test_dict(\n",
    "        feed_dict_test=kwargs_feed_dict_test_seq_len_rnn)\n",
    "\n",
    "    ## GRU MRR ##\n",
    "    [_, _, mrr_GRU, _, _] = \\\n",
    "            rnn_GRU_model.run_eval()\n",
    "\n",
    "    ## LSTM MRR ##\n",
    "    [_, _, mrr_LSTM, _, _] = \\\n",
    "            rnn_LSTM_model.run_eval()\n",
    "    \n",
    "    ## log MRR for RNNs ##\n",
    "    mrr_per_seq_len_GRU[seq_len] = mrr_GRU  # GRU\n",
    "    mrr_per_seq_len_LSTM[seq_len] = mrr_LSTM  # LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Model', 'SVM'),\n",
       "             ('Similarity', 1.0),\n",
       "             (1, 0.12897273312746454),\n",
       "             (2, 0.13348470937339363),\n",
       "             (3, 0.13905204961356313),\n",
       "             (4, 0.14902429150980973),\n",
       "             (5, 0.15500087165580131),\n",
       "             (6, 0.17265490754140878),\n",
       "             (7, 0.19342850818457338),\n",
       "             (8, 0.21341119554515092),\n",
       "             (9, 0.22152615497582026),\n",
       "             (10, 0.2422486953461567),\n",
       "             (11, 0.25970842139813521),\n",
       "             (12, 0.2622546100585334),\n",
       "             (13, 0.27735098100789629),\n",
       "             (14, 0.29682048834791974),\n",
       "             (15, 0.30138664227540757),\n",
       "             (16, 0.31978994105400393),\n",
       "             (17, 0.32711502151003441),\n",
       "             (18, 0.33648139714425218),\n",
       "             (19, 0.35623619396217499),\n",
       "             (20, 0.35966155733044347),\n",
       "             (21, 0.37935742106102505),\n",
       "             (22, 0.39430264865966463),\n",
       "             (23, 0.41985483949658275),\n",
       "             (24, 0.45114114157329338),\n",
       "             (25, 0.46556974009872426),\n",
       "             (26, 0.48233820552705814),\n",
       "             (27, 0.50415053858731407),\n",
       "             (28, 0.53438889169221993),\n",
       "             (29, 0.56305688586871361),\n",
       "             (30, 0.58432478240915831),\n",
       "             (31, 0.62764865376613466),\n",
       "             (32, 0.6528939045888198),\n",
       "             (33, 0.67850068113628115),\n",
       "             (34, 0.6977680874647868),\n",
       "             (35, 0.7212136078536876),\n",
       "             (36, 0.74157696049864374),\n",
       "             (37, 0.76714976799722556),\n",
       "             (38, 0.78502138163155111),\n",
       "             (39, 0.80333831761128816),\n",
       "             (40, 0.81710231535754951),\n",
       "             (41, 0.84312169312169327),\n",
       "             (42, 0.8582321006049819),\n",
       "             (43, 0.8686306160882431),\n",
       "             (44, 0.88460676172540564),\n",
       "             (45, 0.90002690341673397),\n",
       "             (46, 0.91019639494215776),\n",
       "             (47, 0.91659940812483187),\n",
       "             (48, 0.92978208232445514),\n",
       "             (49, 0.92507398439601829),\n",
       "             (50, 0.93637341942426688),\n",
       "             (51, 0.93872746838848531),\n",
       "             (52, 0.93872746838848531),\n",
       "             (53, 0.94155232714554749),\n",
       "             (54, 0.94739036857680925),\n",
       "             (55, 0.95661824051654565),\n",
       "             (56, 0.95680656443368317),\n",
       "             (57, 0.95680656443368317),\n",
       "             (58, 0.95680656443368317),\n",
       "             (59, 0.95680656443368317),\n",
       "             (60, 0.95963142319074524),\n",
       "             (61, 0.95963142319074524),\n",
       "             (62, 0.95963142319074524),\n",
       "             (63, 0.95963142319074524),\n",
       "             (64, 0.95963142319074524),\n",
       "             (65, 0.95963142319074524),\n",
       "             (66, 0.95963142319074524),\n",
       "             (67, 0.95963142319074524),\n",
       "             (68, 0.95963142319074524),\n",
       "             (69, 0.95963142319074524),\n",
       "             (70, 0.95963142319074524),\n",
       "             (71, 0.95963142319074524),\n",
       "             (72, 0.95963142319074524),\n",
       "             (73, 0.95963142319074524),\n",
       "             (74, 0.95963142319074524),\n",
       "             (75, 0.95963142319074524),\n",
       "             (76, 0.95963142319074524),\n",
       "             (77, 0.95963142319074524),\n",
       "             (78, 0.95963142319074524),\n",
       "             (79, 0.95963142319074524),\n",
       "             (80, 0.95963142319074524)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_per_seq_len_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Model', 'GRU'),\n",
       "             ('Similarity', 1.0),\n",
       "             (1, 0.45698613),\n",
       "             (2, 0.65790641),\n",
       "             (3, 0.83949959),\n",
       "             (4, 0.92349344),\n",
       "             (5, 0.9463343),\n",
       "             (6, 0.95853901),\n",
       "             (7, 0.96136391),\n",
       "             (8, 0.96230561),\n",
       "             (9, 0.96230561),\n",
       "             (10, 0.96230561),\n",
       "             (11, 0.96227062),\n",
       "             (12, 0.96227062),\n",
       "             (13, 0.96227062),\n",
       "             (14, 0.96227062),\n",
       "             (15, 0.96228719),\n",
       "             (16, 0.96227062),\n",
       "             (17, 0.96228719),\n",
       "             (18, 0.96227062),\n",
       "             (19, 0.96228719),\n",
       "             (20, 0.96228719),\n",
       "             (21, 0.96228719),\n",
       "             (22, 0.96228719),\n",
       "             (23, 0.96227062),\n",
       "             (24, 0.96490711),\n",
       "             (25, 0.96511203),\n",
       "             (26, 0.96509546),\n",
       "             (27, 0.97057337),\n",
       "             (28, 0.97055686),\n",
       "             (29, 0.97055686),\n",
       "             (30, 0.97055686),\n",
       "             (31, 0.97057337),\n",
       "             (32, 0.97057337),\n",
       "             (33, 0.97043884),\n",
       "             (34, 0.97043884),\n",
       "             (35, 0.97043884),\n",
       "             (36, 0.97057337),\n",
       "             (37, 0.97057337),\n",
       "             (38, 0.97057337),\n",
       "             (39, 0.97043884),\n",
       "             (40, 0.97043884),\n",
       "             (41, 0.97043884),\n",
       "             (42, 0.97033793),\n",
       "             (43, 0.97033793),\n",
       "             (44, 0.97033793),\n",
       "             (45, 0.97033793),\n",
       "             (46, 0.97033793),\n",
       "             (47, 0.97033793),\n",
       "             (48, 0.97033793),\n",
       "             (49, 0.97033793),\n",
       "             (50, 0.97033793),\n",
       "             (51, 0.97033793),\n",
       "             (52, 0.97033793),\n",
       "             (53, 0.97033793),\n",
       "             (54, 0.97033793),\n",
       "             (55, 0.97033793),\n",
       "             (56, 0.97316283),\n",
       "             (57, 0.97316283),\n",
       "             (58, 0.97316283),\n",
       "             (59, 0.97316283),\n",
       "             (60, 0.97316283),\n",
       "             (61, 0.97316283),\n",
       "             (62, 0.97316283),\n",
       "             (63, 0.97316283),\n",
       "             (64, 0.97316283),\n",
       "             (65, 0.97316283),\n",
       "             (66, 0.97316283),\n",
       "             (67, 0.97316283),\n",
       "             (68, 0.97316283),\n",
       "             (69, 0.97316283),\n",
       "             (70, 0.97316283),\n",
       "             (71, 0.97316283),\n",
       "             (72, 0.97316283),\n",
       "             (73, 0.97316283),\n",
       "             (74, 0.97316283),\n",
       "             (75, 0.97316283),\n",
       "             (76, 0.97316283),\n",
       "             (77, 0.97316283),\n",
       "             (78, 0.97316283),\n",
       "             (79, 0.97316283),\n",
       "             (80, 0.97316283)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_per_seq_len_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Model', 'LSTM'),\n",
       "             ('Similarity', 1.0),\n",
       "             (1, 0.12755091),\n",
       "             (2, 0.15693289),\n",
       "             (3, 0.18570159),\n",
       "             (4, 0.21841292),\n",
       "             (5, 0.23627855),\n",
       "             (6, 0.25239888),\n",
       "             (7, 0.25706753),\n",
       "             (8, 0.26185051),\n",
       "             (9, 0.26929688),\n",
       "             (10, 0.30441821),\n",
       "             (11, 0.31336775),\n",
       "             (12, 0.30765662),\n",
       "             (13, 0.30376804),\n",
       "             (14, 0.30429891),\n",
       "             (15, 0.30822772),\n",
       "             (16, 0.32288352),\n",
       "             (17, 0.31979552),\n",
       "             (18, 0.3234525),\n",
       "             (19, 0.33504808),\n",
       "             (20, 0.34580347),\n",
       "             (21, 0.35354766),\n",
       "             (22, 0.37389383),\n",
       "             (23, 0.38697669),\n",
       "             (24, 0.39719197),\n",
       "             (25, 0.41831061),\n",
       "             (26, 0.43976787),\n",
       "             (27, 0.43077242),\n",
       "             (28, 0.4432151),\n",
       "             (29, 0.45658615),\n",
       "             (30, 0.44416267),\n",
       "             (31, 0.48833033),\n",
       "             (32, 0.51360661),\n",
       "             (33, 0.53357875),\n",
       "             (34, 0.54940414),\n",
       "             (35, 0.56543988),\n",
       "             (36, 0.57735628),\n",
       "             (37, 0.61185449),\n",
       "             (38, 0.63059127),\n",
       "             (39, 0.63775575),\n",
       "             (40, 0.65402001),\n",
       "             (41, 0.66088045),\n",
       "             (42, 0.68374979),\n",
       "             (43, 0.71163964),\n",
       "             (44, 0.73119628),\n",
       "             (45, 0.76583242),\n",
       "             (46, 0.78119999),\n",
       "             (47, 0.80189413),\n",
       "             (48, 0.81726462),\n",
       "             (49, 0.82968348),\n",
       "             (50, 0.83650589),\n",
       "             (51, 0.83692193),\n",
       "             (52, 0.83876795),\n",
       "             (53, 0.85140872),\n",
       "             (54, 0.86480099),\n",
       "             (55, 0.86632937),\n",
       "             (56, 0.86732739),\n",
       "             (57, 0.86999881),\n",
       "             (58, 0.88399434),\n",
       "             (59, 0.8890636),\n",
       "             (60, 0.89554179),\n",
       "             (61, 0.89902604),\n",
       "             (62, 0.90688276),\n",
       "             (63, 0.91374725),\n",
       "             (64, 0.9116928),\n",
       "             (65, 0.91803747),\n",
       "             (66, 0.92870921),\n",
       "             (67, 0.93247563),\n",
       "             (68, 0.93530047),\n",
       "             (69, 0.94000864),\n",
       "             (70, 0.9371838),\n",
       "             (71, 0.94000864),\n",
       "             (72, 0.94000864),\n",
       "             (73, 0.94283348),\n",
       "             (74, 0.94283348),\n",
       "             (75, 0.94565839),\n",
       "             (76, 0.94565839),\n",
       "             (77, 0.94565839),\n",
       "             (78, 0.94565839),\n",
       "             (79, 0.94565839),\n",
       "             (80, 0.94565839)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_per_seq_len_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the 3 results (SVM, LSTM, GRU) to pickle file format\n",
    "collected_results_per_seq_len_dir = 'rnn_results/results_per_seq_len/'\n",
    "mrr_seq_len_fname = collected_results_per_seq_len_dir + \\\n",
    "    'rnn_svm_mrr_per_seq_len_sim_{}.p'.format(suggestion_str)\n",
    "\n",
    "save(fname=mrr_seq_len_fname, \n",
    "     obj=[mrr_per_seq_len_SVM, \n",
    "          mrr_per_seq_len_LSTM, \n",
    "          mrr_per_seq_len_GRU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.utils.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "print_tensors_in_checkpoint_file(\n",
    "    file_name='/home/yarden/git/Automated_categorization_medication/test_HERE' ,\n",
    "                                 tensor_name=None,\n",
    "#                                  all_tensors=True\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
