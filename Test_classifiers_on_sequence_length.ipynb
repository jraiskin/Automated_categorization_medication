{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "from utils.utils_nn import *\n",
    "from utils.utils_baseline_svm import *\n",
    "from utils.Rnn_model import Rnn_model\n",
    "\n",
    "from utils.kwargs_file import kwargs_lin_data_init, kwargs_svm, \\\n",
    "    kwargs_rnn, kwargs_neural_data_init\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed())\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "import os\n",
    "\n",
    "# import random\n",
    "# random.seed(seed())\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup hyper paramteres and classifiers configurations\n",
    "# SVM ========================\n",
    "# kwargs_lin_data_init = nice_dict({'mk_chars': True, \n",
    "#                             'model': 'linear', \n",
    "#                             'char_filter': 100, 'allowed_chars': None, \n",
    "#                             'mk_ngrams': True, 'ngram_width': 5, \n",
    "#                             'ngram_filter': 10, 'allowed_ngrams': None, \n",
    "#                             'keep_infreq_labels': False, 'label_count_thresh': 10, \n",
    "#                             'valid_ratio': 0.25, \n",
    "#                             'scale_func': unscale, 'to_permute': True, })\n",
    "\n",
    "# kwargs_svm = nice_dict({'C': 0.1,  # penalty term\n",
    "#                         'decision_function_shape': 'ovr',  # one-vs-rest (‘ovr’) / one-vs-one (‘ovo’) \n",
    "#                         'random_state': seed(), \n",
    "#                         'kernel': 'linear', \n",
    "#                         'gamma': 'auto' ,  # kernel coef for ‘rbf’, ‘poly’ and ‘sigmoid’. ‘auto’ -> 1/n_features\n",
    "#                         'probability': True,  # enable probability estimates \n",
    "#                         'shrinking': True,  # use the shrinking heuristic \n",
    "#                         'max_iter': -1  # -1 mean no limitation \n",
    "#                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RNN ========================\n",
    "# kwargs_neural_data_init = \\\n",
    "#     {'mk_chars': True, \n",
    "#                'model': 'neural', \n",
    "#                'char_filter': 100, 'allowed_chars': None, \n",
    "#                'mk_ngrams': False, 'ngram_width': 5, \n",
    "#                'ngram_filter': 10, 'allowed_ngrams': None, \n",
    "#                'keep_infreq_labels': False, 'label_count_thresh': 10, \n",
    "#                'valid_ratio': 0.25, \n",
    "#                'scale_func': unscale, 'to_permute': True, }\n",
    "\n",
    "# kwargs_simple_rnn = nice_dict({\n",
    "#     # log\n",
    "#     'log_dir': 'experiments/logdir_exper_4_20_GRU/', \n",
    "#     'del_log': False, \n",
    "#     # preprocessing and data\n",
    "#     'top_k': 5, \n",
    "#     'seed': seed(), \n",
    "#     # learning hyper-params\n",
    "#     'learn_rate': 1E-2, \n",
    "#     'dynamic_learn_rate': False, \n",
    "#     'rnn_type': 'GRU',\n",
    "#     'bidirection': False, \n",
    "#     'char_embed_dim': 4, \n",
    "#     'one_hot': True,\n",
    "#     'hidden_state_size': 128, \n",
    "#     'keep_prob': 0.7, \n",
    "#     # noisy activation hyper params\n",
    "#     'activation_function': 'noisy_tanh',  # tf.tanh / 'noisy_tanh'\n",
    "#     'learn_p_delta_scale': False,   # noise scale param in noisy activation\n",
    "#     'noise_act_alpha': 0.9,  # mixing in the linear activation\n",
    "#     'noise_act_half_normal': False,\n",
    "#     # regularization constants\n",
    "#     'l2_weight_reg': 1E-3, \n",
    "#     'target_rep': True, \n",
    "#     'target_rep_weight': 0.3, \n",
    "#     # training settings\n",
    "#     'epochs': 20,\n",
    "#     'summary_step': 10, \n",
    "#     'save_step': np.inf,\n",
    "#     'to_save': False, \n",
    "#     'verbose_summary': False\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kwargs_simple_rnn.log_dir = 'experiments/logdir_exper_4_20_GRU/'\n",
    "\n",
    "# GRU,bidir=F,noisy_tanh,learn_p=F,noise_alpha=0.9,noise_half_normal=F,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=0.7,one_hot,hidden_state_size=128,l2_wieght_reg=1.0E-03,target_rep_weight=0.3\n",
    "rnn_dir_name = 'GRU,bidir=F,noisy_tanh,learn_p=F,noise_alpha=0.9,noise_half_normal=F,keep_infreq_labels=F,learn_rate=1.0E-02,keep_prob=0.7,one_hot,hidden_state_size=128,l2_wieght_reg=1.0E-03,target_rep_weight=0.3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM ========================\n",
    "# vectorizer transforms dict into sparse matrix\n",
    "v = DictVectorizer(sparse=True)\n",
    "\n",
    "# load data\n",
    "x_train_svm, x_val_svm, \\\n",
    "    y_train_svm, y_val_svm, \\\n",
    "    allowed_ngrams = \\\n",
    "    data_load_preprocess(**{**kwargs_lin_data_init, \n",
    "                            **{'linear_counters': False}})\n",
    "\n",
    "# create and fit classifier\n",
    "# create a sparse X matrix with character and n-grams features\n",
    "X_train_svm = v.fit_transform([Counter(elem) for elem in x_train_svm])\n",
    "X_val_svm = v.transform([Counter(elem) for elem in x_val_svm])\n",
    "\n",
    "print('X_train_svm (sparse) matrix, of size {} by {} has been created.'\n",
    "      .format(X_train_svm.get_shape()[0], \n",
    "              X_train_svm.get_shape()[1]))  # vectorized\n",
    "\n",
    "svm_clf = svm.SVC(**kwargs_svm)\n",
    "\n",
    "# print(svm_clf)\n",
    "\n",
    "svm_clf.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# array to hold log probabilities (takes a bit longer to calc)\n",
    "pred_prob = svm_clf.predict_log_proba(X_val_svm)\n",
    "# makes y into array with the same shape as the log prob\n",
    "y_val_svm_dense = y_to_dense(y=y_val_svm, \n",
    "                         classes=svm_clf.classes_)\n",
    "\n",
    "print('Accuracy on validation set is {:.3f}'.\n",
    "      format(svm_clf.score(X_val_svm, \n",
    "                           y_val_svm)))\n",
    "\n",
    "print('Mean Reciprocal Rank is {:.3f}'\n",
    "      .format(mean_reciprocal_rank(y_val_svm_dense, \n",
    "                                   pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mrr = mean_reciprocal_rank(\n",
    "    y_val_svm_dense, \n",
    "    pred_prob)\n",
    "\n",
    "acc1 = in_top_k(\n",
    "    y_val_svm_dense, \n",
    "    pred_prob, \n",
    "    1)\n",
    "\n",
    "top5 = in_top_k(\n",
    "    y_val_svm_dense, \n",
    "    pred_prob, \n",
    "    5)\n",
    "\n",
    "print(mrr, top5, acc1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_first_k_chars(input=x_train_svm, k=7, \n",
    "                   model='linear', \n",
    "                   ngram_width=kwargs_lin_data_init.ngram_width, \n",
    "                   mk_ngrams=kwargs_lin_data_init.mk_ngrams, \n",
    "                   allowed_ngrams=allowed_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "# load data (only validation data, since we're not training RNN now)\n",
    "_, _, x_feed_val_rnn, y_feed_val_rnn,\\\n",
    "    char_int, char_int_inv, label_int, label_int_inv, \\\n",
    "    statistics_dict =\\\n",
    "    data_load_preprocess(**kwargs_neural_data_init)\n",
    "\n",
    "kwargs_simple_rnn = {**kwargs_simple_rnn, \n",
    "                      **statistics_dict}\n",
    "\n",
    "kwargs_simple_rnn = nice_dict({**kwargs_simple_rnn, \n",
    "                               **{'scale_func': kwargs_neural_data_init['scale_func'], \n",
    "                                  'keep_infreq_labels': kwargs_neural_data_init['keep_infreq_labels']}})\n",
    "\n",
    "# validation data\n",
    "X_val_rnn, _, Y_val_rnn = index_transorm_xy(x=x_feed_val_rnn, \n",
    "                                    y=y_feed_val_rnn, \n",
    "                                    char_int=char_int, \n",
    "                                    label_int=label_int, \n",
    "                                    **kwargs_simple_rnn)\n",
    "\n",
    "kwargs_feed_dict_test = {'x': X_val_rnn, \n",
    "                         'y': Y_val_rnn}\n",
    "\n",
    "# create classifier and load weights\n",
    "Rnn_clf = Rnn_model(\n",
    "    feed_dict_test=kwargs_feed_dict_test, \n",
    "    **{**kwargs_simple_rnn, \n",
    "       **{}}  # 'epochs': 100\n",
    ")\n",
    "\n",
    "\n",
    "# Rnn_clf.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hparam_str = make_hparam_string(**kwargs_simple_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(hparam_str)\n",
    "print(rnn_dir_name)\n",
    "print(hparam_str == rnn_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rnn_clf.restore(cp_path=os.path.join(kwargs_simple_rnn.log_dir, hparam_str))\n",
    "Rnn_clf.restore(cp_path=os.path.join(kwargs_simple_rnn.log_dir, rnn_dir_name))\n",
    "# Rnn_clf.restore(cp_path=rnn_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[accuracy, cost, recip_rank, top_k] = rnn_new.run_eval()\n",
    "print('accuracy is {:.5f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_new.update_test_dict(kwargs_feed_dict_train)\n",
    "[accuracy, cost, recip_rank, top_k] = rnn_new.run_eval()\n",
    "print('accuracy is {:.5f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_first_k_chars(input=X_train, k=2, \n",
    "                       model='neural', \n",
    "                       char_int=char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate first_k_characters sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect evaulation metrics for sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
