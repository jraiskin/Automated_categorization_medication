{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn import svm\n",
    "# from sklearn.metrics import accuracy_score  # gt, pred\n",
    "\n",
    "from utils.utils import user_opt_gen, nice_dict, seed, pcp1, pcp2, pcp3, pcp4\n",
    "from utils.utils_baseline_svm import filter_dict_by_val_atleast, char_freq_map\n",
    "\n",
    "# from collections import Counter\n",
    "# from math import isnan\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_dir_content(path):\n",
    "    if tf.gfile.Exists(path):\n",
    "#         tf.gfile.DeleteRecursively(path)\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_opt = user_opt_gen()\n",
    "\n",
    "main_data = pd.read_csv(user_opt['data_path'], \n",
    "                         sep=';', \n",
    "                         header=0, \n",
    "                         encoding='cp850')\n",
    "\n",
    "# only observations with ATC labels\n",
    "main_data_labeled = main_data.loc[[isinstance(k, str) for k in main_data['ATC']],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir/\n"
     ]
    }
   ],
   "source": [
    "# import urllib\n",
    "\n",
    "n = len(main_data_labeled)\n",
    "\n",
    "x = main_data_labeled['FREETXT'][:n]\n",
    "y = main_data_labeled['ATC'][:n]\n",
    "\n",
    "kwargs_tf_simple = nice_dict({'log_dir': 'logdir/', \n",
    "                              'GIST_URL': 'https://gist.githubusercontent.com/dandelionmane/4f02ab8f1451e276fea1f165a20336f1/raw/dfb8ee95b010480d56a73f324aca480b3820c180/', \n",
    "                              'del_log': True, \n",
    "                              'char_filter': 100})\n",
    "\n",
    "if kwargs_tf_simple.del_log: remove_dir_content(kwargs_tf_simple.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter by character, appear at least 'char_filter' times in the input\n",
    "filter_keys_chars = list(\n",
    "    filter_dict_by_val_atleast(\n",
    "        input_dict=char_freq_map(input_data=x), \n",
    "        value=kwargs_tf_simple.char_filter)\n",
    "    .keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create list of character lists\n",
    "x_char = [list(line) for line in x]\n",
    "x_char_filtered = []\n",
    "unknown = '<unk-char>'\n",
    "# replace chars not in 'filter_keys_chars' with 'unknown'\n",
    "for line in x_char:\n",
    "    x_char_filtered.append([char if (char in filter_keys_chars) else unknown for char in line])\n",
    "\n",
    "# can check\n",
    "# for ind in range(10):\n",
    "#     print(x_char_filtered[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_labels = len(y.unique())\n",
    "# number of unique characters iin input ('x_char_filtered')\n",
    "n_char = len(set([char for line in x_char_filtered for char in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lstm_unit(*, \n",
    "              input, \n",
    "              size_in, \n",
    "              size_out, \n",
    "              name=\"LSTM\", \n",
    "              activate = tf.nn.relu, \n",
    "              n_input, \n",
    "              n_steps, \n",
    "              n_hidden):\n",
    "    # activate can be (commonly):\n",
    "    # tf.sigmoid\n",
    "    # tf.nn.relu\n",
    "    # tf.tanh\n",
    "    # tf.nn.relu6\n",
    "    assert activate in [tf.nn.relu, \n",
    "                        tf.nn.relu6, \n",
    "                        tf.sigmoid, \n",
    "                        tf.tanh], 'Please choose activation function from the given set'\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        \n",
    "        \n",
    "        # Permuting batch_size and n_steps\n",
    "        x = tf.transpose(input, [1, 0, 2])\n",
    "        # Reshape to (n_steps*batch_size, n_input)\n",
    "        x = tf.reshape(x, [-1, n_input])\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        x = tf.split(0, n_steps, x)\n",
    "        \n",
    "#         lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        lstm_fw_cell = tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        \n",
    "        output, state = lstm_fw_cell(x, state, dtype=tf.float32)        \n",
    "        \n",
    "        lin_activations = tf.matmul(output[-1], w) + b\n",
    "        act = activate(lin_activations)\n",
    "        \n",
    "#         act = activate(tf.matmul(input, w) + b)\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "    \n",
    "def make_hparam_string(learning_rate, fc, conv):\n",
    "    conv_param = 'conv={:d}'.format(conv)\n",
    "    fc_param = 'conv={:d}'.format(fc)\n",
    "#     return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "    return 'lr_{:.0E},{},{}'.format(learning_rate, conv_param, fc_param)\n",
    "\n",
    "\n",
    "def simple_lstm_model(learn_rate, conv, lstm, hparam_str):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    tf.set_random_seed(seed())\n",
    "    \n",
    "    \n",
    "# https://www.tensorflow.org/tutorials/recurrent\n",
    "# https://www.tensorflow.org/programmers_guide/reading_data#preloaded_data\n",
    "# https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\n",
    "# https://www.tensorflow.org/api_guides/python/nn#Embeddings\n",
    "# https://github.com/dhwajraj/deep-siamese-text-similarity/blob/master/siamese_network.py\n",
    "\n",
    "# source code, from lines 125, 141\n",
    "# https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kwargs_tf_simple.log_dir\n",
    "# os.path.join(os.path.curdir + '/logdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=kwargs_tf_simple.log_dir + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "urllib.request.urlretrieve(kwargs_tf_simple.GIST_URL + 'labels_1024.tsv', kwargs_tf_simple.log_dir + 'labels_1024.tsv')\n",
    "urllib.request.urlretrieve(kwargs_tf_simple.GIST_URL + 'sprite_1024.png', kwargs_tf_simple.log_dir + 'sprite_1024.png')\n",
    "\n",
    "pcp1()\n",
    "\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    tf.set_random_seed(seed())\n",
    "\n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "        conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "    else:\n",
    "        conv1 = conv_layer(x_image, 1, 64, \"conv\")\n",
    "        conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "        embedding_input = fc1\n",
    "        embedding_size = 1024\n",
    "        logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7*7*64\n",
    "        logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits, labels=y), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(kwargs_tf_simple.log_dir + hparam)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = kwargs_tf_simple.log_dir + 'sprite_1024.png'\n",
    "    embedding_config.metadata_path = kwargs_tf_simple.log_dir + 'labels_1024.tsv'\n",
    "    # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "    pcp3()\n",
    "    \n",
    "    for i in range(1000 + 1):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i % 5 == 0:\n",
    "            \n",
    "#             pcp4()\n",
    "            \n",
    "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "            print('Iteration number {}, Accuracy is currently {}'.format(i, train_accuracy))\n",
    "        if i % 500 == 0:\n",
    "            sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(kwargs_tf_simple.log_dir, \"model.ckpt\"), i)\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "def main():\n",
    "    \n",
    "#     tf.set_random_seed(seed())\n",
    "    \n",
    "    # You can try adding some more learning rates\n",
    "    for learning_rate in [1E-4]:\n",
    "\n",
    "        # Include \"False\" as a value to try different model architectures\n",
    "        for use_two_fc in [False]:\n",
    "            for use_two_conv in [True]:\n",
    "                # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "                \n",
    "                pcp2()\n",
    "                \n",
    "                hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "                print('Starting run for %s' % hparam)\n",
    "\n",
    "                # Actually run with the new settings\n",
    "                mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteration number 925, Accuracy is currently 0.5\n",
    "# Iteration number 930, Accuracy is currently 0.6000000238418579\n",
    "# Iteration number 935, Accuracy is currently 0.5699999928474426\n",
    "# Iteration number 940, Accuracy is currently 0.550000011920929\n",
    "# Iteration number 945, Accuracy is currently 0.5400000214576721\n",
    "# Iteration number 950, Accuracy is currently 0.5799999833106995\n",
    "# Iteration number 955, Accuracy is currently 0.6200000047683716\n",
    "# Iteration number 960, Accuracy is currently 0.5199999809265137\n",
    "# Iteration number 965, Accuracy is currently 0.5400000214576721\n",
    "# Iteration number 970, Accuracy is currently 0.6700000166893005\n",
    "# Iteration number 975, Accuracy is currently 0.5899999737739563\n",
    "# Iteration number 980, Accuracy is currently 0.46000000834465027\n",
    "# Iteration number 985, Accuracy is currently 0.5699999928474426\n",
    "# Iteration number 990, Accuracy is currently 0.5899999737739563\n",
    "# Iteration number 995, Accuracy is currently 0.550000011920929\n",
    "# Iteration number 1000, Accuracy is currently 0.5799999833106995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
